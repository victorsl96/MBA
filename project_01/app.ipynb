{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Será que podemos comparar ideologias políticas a partir de tweets?\n",
    "\n",
    "ideologia: conjunto de convicções filosóficas, sociais, políticas etc. de um indivíduo ou grupo de indivíduos.\n",
    "\n",
    "Comparações:\n",
    "    - análise gráfica comparativa da frequência de palavras ou relacionadas a tópicos: \n",
    "        religião, educação, orientação sexual, identidade de gênero, economia, saúde, porte de armas, combate a pobreza\n",
    "            ex: Quantidade de tweets do Bolsonaro falando sobre drogas é muito maior que a do Lula, que mostra maior favor a política anti-drogas\n",
    "            (Buscar se a quantidade de palavras segue a mesma tendência)\n",
    "\n",
    "    - Comparação percentual entre palavras específicas em relação ao total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports section\n",
    "import re\n",
    "import pandas as pd\n",
    "import unicodedata as uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    '''Extract the JSON data and save it in a dataframe'''\n",
    "    # Open json files and read into dataframes\n",
    "    with open('dataset/jairbolsonaro.json','r') as file_01:\n",
    "        df_01=pd.read_json(file_01)\n",
    "    with open('dataset/LulaOficial.json','r') as file_02:\n",
    "        df_02=pd.read_json(file_02)\n",
    "    # rename columns inplace\n",
    "    df_01.rename(columns={'full_text':'Bolsonaro'}, inplace=True)\n",
    "    df_02.rename(columns={'full_text':'Lula'}, inplace=True)\n",
    "    # concatenate dataframes into one dataframe\n",
    "    cols=[df_01['Bolsonaro'], df_02['Lula']]\n",
    "    dataframe=pd.concat(cols,axis=1)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(tweet):\n",
    "    '''Normalizes every word, removes links, hashtags, numbers, mentions, pontuation, emogis and removes stopwords from a single tweet and returns a list with the remaining words'''\n",
    "    # input as single tweet string\n",
    "    # output as list of string words\n",
    "    stopwords=('de', 'a', 'pra', 'fazer','estar','lula','none', 'o', 'que', 'd','e', 'do', 'da', 'em', 'um', 'nao', 'para', 'e', 'com', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'foi', 'ao', 'ele', 'das', 'tem', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'ha', 'nos', 'ja', 'esta', 'eu', 'também', 'so', 'pelo', 'pela', 'ate', 'isso', 'ela', 'entre', 'era', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'estao', 'voce', 'tinha', 'foram', 'essa', 'num', 'nem', 'suas', 'meu', 'minha', 'numa', 'pelos', 'elas', 'havia', 'seja', 'qual', 'sera', 'tenho', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'fosse', 'dele', 'tu', 'te', 'voces', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'esta', 'estamos', 'estao', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estavamos', 'estavam', 'estivera', 'estiveramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivessemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'ha', 'havemos', 'hao', 'houve', 'houvemos', 'houveram', 'houvera', 'houveramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvessemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houvera', 'houveremos', 'houverao', 'houveria', 'houveriamos', 'houveriam', 'sou', 'somos', 'sao', 'era', 'eramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'foramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fossemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'sera', 'seremos', 'serao', 'seria', 'seriamos', 'seriam', 'tenho', 'tem', 'temos', 'tem', 'tinha', 'tinhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tiveramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivessemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'tera', 'teremos', 'terao', 'teria', 'teriamos', 'teriam')\n",
    "    if type(tweet) != str:\n",
    "        tweet='none'\n",
    "    # normalize text and make all letters lowercase\n",
    "    tweet = uni.normalize('NFD', tweet).encode('ASCII', 'ignore').decode('utf-8').lower()\n",
    "    \n",
    "    # remove links\n",
    "    url_pattern=r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\\\".,<>?«»“”‘’]))'\n",
    "    \n",
    "    # remove hashtags\n",
    "    tags_pattern=r'\\#([a-zA-Z0-9_]{1,50})'\n",
    "    \n",
    "    # remove mentions\n",
    "    mentions_pattern=r'\\@([a-zA-Z0-9_]{1,50})'    \n",
    "    \n",
    "    # remove ponctuation, emogis and numbers and making sure there's only words in the output\n",
    "    rest_pattern=r'[^\\w\\s]+|\\d+'\n",
    "    \n",
    "    # apply all patterns deleting all matched objects\n",
    "    # patterns = [url_pattern,tags_pattern,mentions_pattern,rest_pattern]\n",
    "    # for pattern in patterns:\n",
    "    #     tweet = re.sub(pattern,'',tweet)\n",
    "\n",
    "    patterns=re.compile('|'.join([url_pattern,tags_pattern,mentions_pattern,rest_pattern]))\n",
    "\n",
    "    tweet = re.sub(patterns,'',tweet)\n",
    "\n",
    "    clean_tweet=[word for word in tweet.split() if word not in stopwords]\n",
    "    \n",
    "    return clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(tweets):\n",
    "    '''Count the ocurrence of key words in the tweets'''\n",
    "    words={}\n",
    "    for tweet in tweets:\n",
    "        for word in clean(tweet):\n",
    "            if word in words.keys() and type(word)==str:\n",
    "                words[word] += 1\n",
    "            else:\n",
    "                words[word] = 1\n",
    "\n",
    "    return sorted(words.items(),key= lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(data,themes):\n",
    "    '''filters the data based on selected themes'''\n",
    "    result=[]\n",
    "    for theme in themes:\n",
    "        for set in data:\n",
    "            if theme in set:\n",
    "                result.append(set)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data()\n",
    "\n",
    "b_data = data['Bolsonaro'] #list of tweets\n",
    "l_data = data['Lula'] #list of tweets\n",
    "\n",
    "themes = ['saude', 'educacao', 'seguranca', 'economia', 'moradia', 'corrupcao', 'inclusao','armas','pobreza']\n",
    "\n",
    "# both b_count and l_count have all words, filter_data() will select relevant themes from those lists\n",
    "b_count = count_words(b_data) #list of sets of (keyword, ocurrence)\n",
    "l_count = count_words(l_data) #list of sets of (keyword, ocurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = filter_data(b_count,themes)\n",
    "df1 = pd.DataFrame(d1,columns=['Palavra','Bolsonaro'])\n",
    "d2 = filter_data(l_count,themes)\n",
    "df2 = pd.DataFrame(d2,columns=['Palavra','Lula'])\n",
    "df = df1.set_index('Palavra').join(df2.set_index('Palavra'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.plot.barh(color={'Bolsonaro':'blue','Lula':'red'})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e163f6dc755e3f5ee4e51757169cbf4c5bf61c999acb41dad94c865ecb280cf3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
